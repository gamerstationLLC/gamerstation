name: Auto Update LoL Data

on:
  schedule:
    - cron: "30 */2 * * *"
  workflow_dispatch:
    inputs:
      rebuild:
        description: "Rebuild crawl from scratch"
        required: false
        default: "false"

concurrency:
  group: lol-auto-update
  cancel-in-progress: false

permissions:
  contents: write

jobs:
  lol:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Sync with main (pre-build)
        run: |
          set -e
          git fetch origin main
          git checkout main
          git reset --hard origin/main

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install deps
        run: npm ci

      - name: Cache Riot data
        id: riot_cache
        uses: actions/cache@v4
        with:
          path: |
            scripts/riot/cache/matches
            scripts/riot/cache/timelines
            scripts/riot/cache/state
          key: lol-riot-cache-v1-${{ runner.os }}
          restore-keys: |
            lol-riot-cache-v1-${{ runner.os }}
            lol-riot-cache-v1

      - name: Prune old Riot cache (90 days)
        run: |
          set -e
          CUTOFF=$(date -d "90 days ago" +%s)
          for DIR in scripts/riot/cache/matches scripts/riot/cache/timelines; do
            if [ -d "$DIR" ]; then
              find "$DIR" -type f -name "*.json" | while read -r file; do
                mtime=$(stat -c %Y "$file" 2>/dev/null || echo 0)
                if [ "$mtime" -lt "$CUTOFF" ]; then
                  rm -f "$file"
                fi
              done
            fi
          done

      - name: Update LoL static data
        run: npm run lol:update

      - name: Update LoL overrides
        run: npm run lol:update:overrides

      # âœ… NEW: Restore prior meta build snapshots from Blob so finalize can MERGE safely
      - name: Restore meta builds snapshots from Vercel Blob (best-effort)
        if: always()
        run: |
          set +e

          BASE="https://or3vgdqybw6oou7j.public.blob.vercel-storage.com"
          mkdir -p public/data/lol

          echo "Restoring meta_builds_ranked.json (if exists)..."
          curl -fsSL "$BASE/data/lol/meta_builds_ranked.json" -o public/data/lol/meta_builds_ranked.json || true
          ls -lah public/data/lol/meta_builds_ranked.json || true

          echo "Restoring meta_builds_casual.json (if exists)..."
          curl -fsSL "$BASE/data/lol/meta_builds_casual.json" -o public/data/lol/meta_builds_casual.json || true
          ls -lah public/data/lol/meta_builds_casual.json || true

          echo "Restore step done."
          exit 0

      - name: Set crawl mode
        id: mode
        run: |
          set -e
          REBUILD="false"
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            REBUILD="${{ inputs.rebuild }}"
          fi
          echo "rebuild=$REBUILD" >> "$GITHUB_OUTPUT"
          if [ "$REBUILD" = "true" ]; then
            echo "REPROCESS_BOOTSTRAP=1" >> "$GITHUB_ENV"
            echo "REPROCESS_SEEDS=1" >> "$GITHUB_ENV"
            echo "RESET_SEEN_MATCHES=1" >> "$GITHUB_ENV"
            echo "RESET_SEEN_PUUIDS=1" >> "$GITHUB_ENV"
            echo "RESET_CURSORS=1" >> "$GITHUB_ENV"
            echo "MAX_MATCHES_PER_RUN=5000" >> "$GITHUB_ENV"
            echo "MAX_NEW_PUUIDS_PER_RUN=500" >> "$GITHUB_ENV"
            echo "MATCHES_PER_PUUID=20" >> "$GITHUB_ENV"
          else
            echo "REPROCESS_BOOTSTRAP=0" >> "$GITHUB_ENV"
            echo "REPROCESS_SEEDS=0" >> "$GITHUB_ENV"
            echo "RESET_SEEN_MATCHES=0" >> "$GITHUB_ENV"
            echo "RESET_SEEN_PUUIDS=0" >> "$GITHUB_ENV"
            echo "RESET_CURSORS=0" >> "$GITHUB_ENV"
            echo "MAX_MATCHES_PER_RUN=20000" >> "$GITHUB_ENV"
            echo "MAX_NEW_PUUIDS_PER_RUN=4000" >> "$GITHUB_ENV"
            echo "MATCHES_PER_PUUID=100" >> "$GITHUB_ENV"
          fi

      - name: Crawl Riot matches (never fail job)
        env:
          RIOT_API_KEY: ${{ secrets.RIOT_API_KEY }}
          RIOT_REGION: americas
          RIOT_PLATFORM: na1
          LADDER_QUEUE: RANKED_SOLO_5x5
          LADDER_TIER: challenger
          LADDER_MAX_PLAYERS: "250"
          MAX_MATCHES_PER_RUN: ${{ env.MAX_MATCHES_PER_RUN }}
          MAX_NEW_PUUIDS_PER_RUN: ${{ env.MAX_NEW_PUUIDS_PER_RUN }}
          MATCHES_PER_PUUID: ${{ env.MATCHES_PER_PUUID }}
          CHECKPOINT_EVERY: "100"
          USE_TIMELINE: "0"
          REPROCESS_BOOTSTRAP: ${{ env.REPROCESS_BOOTSTRAP }}
          REPROCESS_SEEDS: ${{ env.REPROCESS_SEEDS }}
          RESET_SEEN_MATCHES: ${{ env.RESET_SEEN_MATCHES }}
          RESET_SEEN_PUUIDS: ${{ env.RESET_SEEN_PUUIDS }}
          RESET_CURSORS: ${{ env.RESET_CURSORS }}
          CACHE_SCAN_LIMIT: "0"
          CACHE_MAX_AGE_DAYS: "90"
        run: |
          set +e
          timeout 17940 npm run lol:update:meta
          exit 0

      - name: Finalize meta builds
        if: always()
        run: |
          set +e
          npm run lol:finalize:meta
          exit 0

      - name: Upload meta builds to Blob
        if: always()
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
          # IMPORTANT: left side = local file (repo), right side = blob key/path
          BLOB_UPLOADS: "public/data/lol/meta_builds_ranked.json=data/lol/meta_builds_ranked.json;public/data/lol/meta_builds_casual.json=data/lol/meta_builds_casual.json"
          BLOB_CACHE_SECONDS: "300"
          LOL_PATCH: ${{ github.run_id }}
          BLOB_FORCE_OVERWRITE: "1"
        run: |
          set +e
          if [ -n "$BLOB_READ_WRITE_TOKEN" ]; then
            node scripts/blob/upload-data.mjs || true
          fi
          exit 0

      # -------------------------------------------------------------------
      # Items usage: generate -> merge with existing blob -> overwrite blob
      # -------------------------------------------------------------------

      - name: Build items_usage from latest meta (ranked/casual/combined)
        if: always()
        run: |
          set +e
          npm run lol:build:items-usage || true
          exit 0

      - name: Merge items_usage with existing Blob and overwrite Blob with merged
        if: always()
        env:
          NEXT_PUBLIC_BLOB_BASE_URL: ${{ secrets.NEXT_PUBLIC_BLOB_BASE_URL }}
          BLOB_BASE_URL: ${{ secrets.BLOB_BASE_URL }}
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
          BLOB_CACHE_SECONDS: "300"
          LOL_PATCH: ${{ github.run_id }}
          BLOB_FORCE_OVERWRITE: "1"
        run: |
          set +e

          node - <<'NODE'
          const fs = require("fs");
          const fsp = require("fs/promises");
          const path = require("path");

          const base =
            process.env.NEXT_PUBLIC_BLOB_BASE_URL ||
            process.env.BLOB_BASE_URL ||
            process.env.NEXT_PUBLIC_BLOB_BASE ||
            "";

          const REVALIDATE = 300;

          function clamp01(n) {
            if (!Number.isFinite(n)) return 0;
            return Math.max(0, Math.min(1, n));
          }

          async function fetchJson(url) {
            try {
              const res = await fetch(url, { next: { revalidate: REVALIDATE } });
              if (!res.ok) return null;
              return await res.json();
            } catch {
              return null;
            }
          }

          async function readLocalJson(relCandidates) {
            for (const rel of relCandidates) {
              const abs = path.join(process.cwd(), rel);
              try {
                const raw = await fsp.readFile(abs, "utf8");
                return { json: JSON.parse(raw), abs, rel };
              } catch {}
            }
            return { json: null, abs: null, rel: null };
          }

          async function writeLocalJson(outRel, json) {
            const abs = path.join(process.cwd(), outRel);
            await fsp.mkdir(path.dirname(abs), { recursive: true });
            await fsp.writeFile(abs, JSON.stringify(json, null, 2) + "\n", "utf8");
            return abs;
          }

          function mergeUsage(oldFile, newFile, sourceLabel) {
            const nowIso = new Date().toISOString();

            const oldItems = Array.isArray(oldFile?.items) ? oldFile.items : [];
            const newItems = Array.isArray(newFile?.items) ? newFile.items : [];

            const byItem = new Map();

            function upsertItem(row) {
              if (!row || !Number.isFinite(row.itemId)) return;
              const itemId = Number(row.itemId);

              const prev = byItem.get(itemId) || {
                itemId,
                slug: row.slug || "",
                games: 0,
                wins: 0,
                topChamps: new Map(),
              };

              if (row.slug) prev.slug = row.slug;

              prev.games += Number(row.games || 0);
              prev.wins += Number(row.wins || 0);

              const champs = Array.isArray(row.topChamps) ? row.topChamps : [];
              for (const c of champs) {
                const champId = Number(c?.champId);
                if (!Number.isFinite(champId)) continue;
                const pc = prev.topChamps.get(champId) || { champId, games: 0, wins: 0 };
                pc.games += Number(c.games || 0);
                pc.wins += Number(c.wins || 0);
                prev.topChamps.set(champId, pc);
              }

              byItem.set(itemId, prev);
            }

            for (const r of oldItems) upsertItem(r);
            for (const r of newItems) upsertItem(r);

            const outItems = Array.from(byItem.values()).map((it) => {
              const top = Array.from(it.topChamps.values())
                .map((c) => ({
                  champId: c.champId,
                  games: c.games,
                  wins: c.wins,
                  winrate: c.games > 0 ? clamp01(c.wins / c.games) : 0,
                }))
                .sort((a, b) => b.games - a.games)
                .slice(0, 12);

              return {
                itemId: it.itemId,
                slug: it.slug || "",
                games: it.games,
                wins: it.wins,
                winrate: it.games > 0 ? clamp01(it.wins / it.games) : 0,
                topChamps: top,
              };
            });

            outItems.sort((a, b) => b.games - a.games);

            return {
              generatedAt: nowIso,
              source: sourceLabel,
              patchBucket: newFile?.patchBucket || oldFile?.patchBucket,
              items: outItems,
            };
          }

          async function fetchOldFromBlob(rel) {
            if (!base) return null;

            const url1 = `${base.replace(/\/+$/, "")}/${rel.replace(/^\/+/, "")}`;
            const url2 = `${base.replace(/\/+$/, "")}/public/${rel.replace(/^\/+/, "")}`;

            return (await fetchJson(url1)) || (await fetchJson(url2)) || null;
          }

          async function runOne(source) {
            const rel = `data/lol/items_usage_${source}.json`;

            const localCandidates = [
              path.join("public", rel),
              path.join(rel),
            ];

            const oldRemote = await fetchOldFromBlob(rel);
            const { json: newLocal } = await readLocalJson(localCandidates);

            if (!newLocal?.items?.length && !oldRemote?.items?.length) {
              console.log(`[items_usage:${source}] nothing to merge (no local, no remote)`);
              return null;
            }

            const merged = mergeUsage(oldRemote, newLocal, source);

            const outAbs = await writeLocalJson(path.join("public", rel), merged);
            console.log(`[items_usage:${source}] wrote merged -> ${outAbs}`);

            return path.join("public", rel);
          }

          (async () => {
            const outputs = [];
            for (const source of ["ranked", "casual", "combined"]) {
              const outRel = await runOne(source);
              if (outRel) outputs.push(outRel);
            }

            await fsp.writeFile(
              path.join(process.cwd(), ".items_usage_outputs.txt"),
              outputs.join("\n") + "\n",
              "utf8"
            );

            console.log("[items_usage] outputs:", outputs);
          })().catch((e) => {
            console.error("[items_usage] merge failed:", e);
            process.exit(0);
          });
          NODE

          if [ -n "$BLOB_READ_WRITE_TOKEN" ]; then
            UPLOADS=""
            while IFS= read -r line; do
              [ -z "$line" ] && continue
              rel="${line#public/}"
              if [ -n "$UPLOADS" ]; then
                UPLOADS="${UPLOADS};${rel}=${line}"
              else
                UPLOADS="${rel}=${line}"
              fi
            done < .items_usage_outputs.txt

            echo "BLOB_UPLOADS=$UPLOADS"
            if [ -n "$UPLOADS" ]; then
              BLOB_UPLOADS="$UPLOADS" node scripts/blob/upload-data.mjs || true
            fi
          fi

          exit 0

      - name: Commit & push static data only
        if: always()
        run: |
          set -euo pipefail
          git config user.name "gamerstation-bot"
          git config user.email "actions@users.noreply.github.com"
          CANDIDATES=(
            "public/data/lol/champions_index.json"
            "public/data/lol/champions_full.json"
            "public/data/lol/items.json"
            "public/data/lol/spells_overrides.json"
            "public/data/lol/version.json"
          )
          for p in "${CANDIDATES[@]}"; do
            if [ -e "$p" ]; then
              git add -A "$p"
            fi
          done
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "chore(lol): refresh LoL static"
          for i in 1 2 3 4 5; do
            git fetch origin main
            git pull --no-rebase origin main || true
            if git push origin main; then
              echo "Push succeeded."
              exit 0
            fi
            sleep 5
          done
          echo "Push failed after retries."
          exit 1